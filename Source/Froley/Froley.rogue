module Froley
  uses ParseKit<<Froley>>

$include "Assembler.rogue"
$include "Cmd.rogue"
$include "FroleyError.rogue"
$include "FroleyParser.rogue"
$include "FroleyTokenizer.rogue"
$include "Opcode.rogue"
$include "Pattern.rogue"
$include "Token.rogue"
$include "TokenType.rogue"
$include "VM.rogue"

Launcher( System.command_line_arguments )

class Launcher
  METHODS
    method init( args:String[] )
      local options = String[]
      local targets = String[]
      forEach (arg in args)
        if (arg.begins_with("--")) options.add( arg )
        else                       targets.add( arg )
      endForEach

      init( options, targets )

    method init( options:String[], targets:String[] )
      try
        forEach (option in options)
          which (option.before_first('='))
            others
              throw FroleyError( "Unrecognized option: " + option )
          endWhich
        endForEach

        forEach (target in targets)
          Froley = Froley() # new singleton
          Froley.parse( File(target) )
        endForEach

      catch (error:FroleyError)
        println error
      endTry
endClass

class TokenDef( name:String, type:Int32, symbol=null:String, attributes=0:Int32 )
  METHODS
    method to->String
      return "$=$ ($) [$]" (name,type,symbol,attributes)
endClass

class Froley [singleton]
  PROPERTIES
    token_defs_by_name    = StringTable<<TokenDef>>()
    token_defs_by_type    = Table<<Int32,TokenDef>>()
    last_token_type       = 0

    token_defs_by_section = StringTable<<TokenDef[]>>()
    token_attributes      = LookupList<<Int32>>()

    entry_points          = StringLookupList()

    #{
    id_begin_letter = true
    id_begin_digit  = false
    id_begin_other  = "_"

    id_continue_letter = true
    id_continue_digit  = true
    id_continue_other  = "_"
    }#

  METHODS
    method parse( file:File )
      local source = file.load_as_string
      parse( file.filepath, source )

    method parse( filepath:String, source:String )
      source = collect_definitions_and_extract_code( filepath, source )

      local statements = CmdStatements()
      local parser = FroleyParser()
      parser.set_source( filepath, source )
      parser.consume_eols
      parser.parse_multi_line_statements( statements )

      statements.resolve

      local bytes = Assembler().assemble( statements )
      local vm = VM( bytes )
      vm.tokenize( File("Test2.txt") )

    method collect_definitions_and_extract_code( filepath:String, source:String )->String
      $localDefine PARSING_CONFIGURE   0
      $localDefine PARSING_ATTRIBUTES  1
      $localDefine PARSING_DEFINITIONS 2
      $localDefine PARSING_CODE        3
      local code = StringBuilder( 2048 )
      local cur_section_name = "tokenizer"
      local cur_section_defs : TokenDef[]
      local parse_type = PARSING_CODE
      local buffer = StringBuilder()
      local next_attribute_value = 1
      forEach (line at index in LineReader(source))
        if (line.begins_with('['))  # new section
          code.println  # keep line numbers consistent
          cur_section_name = line.extract_string( "[$]*" )
          which (cur_section_name)
            case "configure"
              parse_type = PARSING_CONFIGURE
            case "attributes"
              parse_type = PARSING_ATTRIBUTES
            case "code"
              parse_type = PARSING_CODE
            others
              parse_type = PARSING_DEFINITIONS
          endWhich

          if (parse_type == PARSING_DEFINITIONS)
            cur_section_defs = section_defs( cur_section_name )
          endIf

          #{
        elseIf (parse_type == PARSING_CONFIGURE)
          code.println  # keep line numbers consistent
          local scanner = Scanner( line, &spaces_per_tab=2 ).[ line=index+1 ]
          discard_whitespace( scanner )
          if (not scanner.has_another) nextIteration
          local config_name = scanner.scan_identifier
          if (config_name is null)
            throw FroleyError( filepath, source, scanner.line, scanner.column, "Expected 'id_begin' or 'id_continue'." )
          endIf
          which (config_name)
            case "id_begin"
              id_begin_letter = false
              id_begin_digit  = false
              id_begin_other  = ""
              discard_whitespace( scanner )
              while (scanner.has_another)
                local id = scanner.scan_identifier
                if (id)
                  if (id == "letter")
                    id_begin_letter = true
                  elseIf (id == "digit")
                    id_begin_digit = true
                  else
                    forEach (ch in id)
                      if (not id_begin_other.contains(ch)) id_begin_other += ch
                    endForEach
                  endIf
                else
                  local chars = scanner.scan_string
                  if (chars)
                    forEach (ch in chars)
                      if (not id_begin_other.contains(ch)) id_begin_other += ch
                    endForEach
                  else
                    local ch = scanner.read
                    if (not id_begin_other.contains(ch)) id_begin_other += ch
                  endIf
                endIf
                discard_whitespace(scanner)
              endWhile

            case "id_continue"
              id_continue_letter = false
              id_continue_digit  = false
              id_continue_other  = ""
              discard_whitespace( scanner )
              while (scanner.has_another)
                local id = scanner.scan_identifier
                if (id)
                  if (id == "letter")
                    id_continue_letter = true
                  elseIf (id == "digit")
                    id_continue_digit = true
                  else
                    forEach (ch in id)
                      if (not id_continue_other.contains(ch)) id_continue_other += ch
                    endForEach
                  endIf
                else
                  local chars = scanner.scan_string
                  if (chars)
                    forEach (ch in chars)
                      if (not id_continue_other.contains(ch)) id_continue_other += ch
                    endForEach
                  else
                    local ch = scanner.read
                    if (not id_continue_other.contains(ch)) id_continue_other += ch
                  endIf
                endIf
                discard_whitespace(scanner)
              endWhile
          endWhich
          }#

        elseIf (parse_type == PARSING_CODE)
          code.println( line )

        elseIf (parse_type == PARSING_ATTRIBUTES)
          code.println  # keep line numbers consistent
          local scanner = Scanner( line, &spaces_per_tab=2 ).[ line=index+1 ]
          discard_whitespace( scanner )
          if (scanner.has_another)
            local name = scanner.scan_identifier
            if (name is null)
              throw FroleyError( filepath, source, scanner.line, scanner.column, "Attribute name expected." )
            endIf

            discard_whitespace( scanner )
            if (scanner.consume('='))
              discard_whitespace( scanner )
              if (not scanner.peek.is_number)
                throw FroleyError( filepath, source, scanner.line, scanner.column, "Attribute value expected, e.g 1, 2, 4, etc." )
              endIf
              next_attribute_value = scanner.scan_int64
            endIf

            token_attributes[ name ] = next_attribute_value
            next_attribute_value *= 2

          endIf
        else
          # Token definitions
          code.println  # keep line numbers consistent
          local scanner = Scanner( line, &spaces_per_tab=2 ).[ line=index+1 ]
          discard_whitespace( scanner )
          if (scanner.has_another)
            local name = scanner.scan_identifier
            if (name is null)
              throw FroleyError( filepath, source, scanner.line, scanner.column, "Token name expected." )
            endIf

            local symbol : String
            discard_whitespace( scanner )
            if (scanner.has_another)
              buffer.clear
              local ch = scanner.peek
              if (ch == '"' or ch == '\'')
                local st = scanner.scan_string
                if (st is null)
                  throw FroleyError( filepath, source, scanner.line, scanner.column, "Unterminated string." )
                endIf
                buffer.print( st )
              else
                while (scanner.has_another and not scanner.consume(' ')) buffer.print( scanner.read )
              endIf
              symbol = buffer->String
            endIf

            local attributes = 0
            discard_whitespace( scanner )
            if (scanner.consume('['))
              discard_whitespace( scanner )
              local first = true
              while (first or scanner.consume(','))
                first = false
                discard_whitespace( scanner )
                local attribute_name = scanner.scan_identifier
                if (attribute_name is null)
                  throw FroleyError( filepath, source, scanner.line, scanner.column, "Attribute name expected." )
                endIf
                if (not token_attributes.contains(attribute_name))
                  throw FroleyError( filepath, source, scanner.line, scanner.column, "Undefined attribute '$'." (attribute_name) )
                endIf
                attributes |= token_attributes[ attribute_name ]
              endWhile
              if (not scanner.consume(']'))
                throw FroleyError( filepath, source, scanner.line, scanner.column, "Closing ']' expected." )
              endIf
            endIf

            discard_whitespace( scanner )
            if (scanner.has_another)
              throw FroleyError( filepath, source, scanner.line, scanner.column, "Syntax error - unexpected '$'." (scanner.peek.to_escaped_ascii) )
            endIf

            local def = token_def( name, cur_section_name )
            def.symbol = symbol
            def.attributes = attributes

          endIf
        endIf
      endForEach
      return code->String

    method discard_whitespace( scanner:Scanner )
      while (scanner.consume(' ')) noAction
      if (scanner.consume('#'))
        while (scanner.has_another) scanner.read
      endIf

    method section_defs( name:String )->TokenDef[]
      local entry = token_defs_by_section.find( name )
      if (entry) return entry.value

      local defs = TokenDef[]
      token_defs_by_section[ name ] = defs
      return defs

    method token_def( token_name:String, cur_section_name=null:String )->TokenDef
      local entry = token_defs_by_name.find( token_name )
      if (entry) return entry.value

      ++last_token_type
      local def = TokenDef( token_name, last_token_type )
      token_defs_by_name[ token_name ] = def
      token_defs_by_type[ def.type ] = def

      if (cur_section_name)
        section_defs( cur_section_name ).add( def )
      endIf
      return def

    method token_def( token_type:Int32 )->TokenDef
      return token_defs_by_type[ token_type ]

endClass

