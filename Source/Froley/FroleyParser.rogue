module Froley
  uses ParseKit<<Froley>>

class FroleyParser : Parser
  PROPERTIES
    parse_expression : ParseRule

  METHODS
    method init
      # expression
      local rule = add( ParseRule("expression") )

      # assignment
      rule = add_nested( RightAssociativeBinaryParseRule("assignment") )
      rule.on( "=", <<CmdAssign>> )

      # comparison
      rule = add_nested( BinaryParseRule("comparison") )
      rule.on( "==", <<CmdCompareEQ>> )
      rule.on( "!=", <<CmdCompareNE>> )
      rule.on( "<",  <<CmdCompareLT>> )
      rule.on( "<=", <<CmdCompareLE>> )
      rule.on( ">",  <<CmdCompareGT>> )
      rule.on( ">=", <<CmdCompareGE>> )

      # term
      rule = add_nested( ParseRule("term") )
      rule.on( "(",
        function (parser:FroleyParser)->Cmd
          parser.must_consume( TokenType.SYMBOL_OPEN_PAREN )
          local result = parser.parse_expression()
          parser.must_consume( TokenType.SYMBOL_CLOSE_PAREN )
          return result
        endFunction
      )
      rule.on( "ch",            <<CmdRegisterCh>> )
      rule.on( "count",         <<CmdRegisterCount>> )
      rule.on( "hasAnother",    <<CmdHasAnother>> )
      rule.on( "identifier",    <<CmdAccess>> )
      rule.on( "integer value", <<CmdLiteralInt32>> )
      rule.on( "literal string",<<CmdLiteralString>> )
      rule.on( "read",          <<CmdRead>> )
      rule.on( "pop",           <<CmdPop>> )
      rule.on( "scanDigits",
        function(parser:FroleyParser)->Cmd
          local t = parser.read  # 'scanDigits'
          local min_digits = parser.read_integer
          local max_digits = min_digits
          if (parser.consume(TokenType.SYMBOL_DOT_DOT)) max_digits = parser.read_integer
          local base = 10
          if (parser.consume(TokenType.KEYWORD_BASE))
            base = parser.read_integer
          endIf
          return CmdScanDigits(t,min_digits,max_digits,base)
        endFunction
      )
      rule.on( "peek",
        function(parser:FroleyParser)->Cmd
          local t = parser.read  # 'peek'
          if (parser.next_is(TokenType.SYMBOL_OPEN_PAREN))
            local expr = parser.parse_expression()
            if (expr.is_integer) return CmdPeekInt32( t, expr->Int32 )
            if (expr.is_count)   return CmdPeekCount( t )
            throw expr.t.error( "'Expected 'peek', 'peek(<integer>)', or 'peek(count)'." )
          else
            return CmdPeek( t )
          endIf
        endFunction
      )
      rule.on( "consume",
        function(parser:FroleyParser)->Cmd
          local t = parser.read  # 'consume'
          if (parser.next_is(TokenType.SYMBOL_OPEN_PAREN))
            local expr = parser.parse_expression()
            t = expr.t
            if (expr.is_integer)                      return CmdConsumeCharacter( t, expr->Int32 )
          endIf
          throw t.error( "'Expected 'consume(<character>)'." )
        endFunction
      )

    method parse_statements( statements:CmdStatements )->Logical
      if (consume_eols)
        parse_multi_line_statements( statements )
        return true
      else
        parse_single_line_statements( statements )
        return false
      endIf

    method parse_multi_line_statements( statements:CmdStatements )
      consume_eols
      while (reader.has_another and not reader.peek.type.is_structural)
        parse_statement( statements, &allow_control_structures )
        while (consume_eols or consume(TokenType.SYMBOL_SEMICOLON)) noAction
      endWhile

    method parse_single_line_statements( statements:CmdStatements )
      while (reader.has_another and not reader.peek.type.is_structural)
        parse_statement( statements, &!allow_control_structures )
        if (not consume(TokenType.SYMBOL_SEMICOLON)) return
        while (consume(TokenType.SYMBOL_SEMICOLON)) noAction

        # Don't let a trailing ';' act as a next-line continuation.
        if (next_is(TokenType.EOL)) escapeWhile
      endWhile

      if (not consume(TokenType.EOL))
        if (not reader.peek.type.is_structural)
          must_consume( TokenType.EOL )  # force an error
        endIf
      endIf

    method parse_statement( statements:CmdStatements, &allow_control_structures )->Logical
      consume_eols
      if (not has_another) return false
      local t = peek
      if (t.type.is_structural) return false

      if (allow_control_structures)
        if (consume(TokenType.KEYWORD_IF))
          local cmd_if = CmdIf( t, parse_expression() )
          if (parse_statements(cmd_if.statements))
            # Multi-line statements
            local outer_if = cmd_if
            while (next_is_else_if(&multi_line))
              consume_eols
              local t2 = read
              local inner_if = CmdIf( t2, parse_expression() )
              parse_multi_line_statements( inner_if.statements )
              ensure outer_if.else_statements
              outer_if.else_statements.add( inner_if )
              outer_if = inner_if
            endWhile
            if (next_is_else(&multi_line))
              consume_eols
              if (next_is(TokenType.KEYWORD_ELSE) and reader.peek(1).type == TokenType.EOL)
                read
                ensure outer_if.else_statements
                parse_multi_line_statements( outer_if.else_statements )
              endIf
            endIf
            must_consume( TokenType.KEYWORD_END_IF )
          else
            # Single line statements
            local outer_if = cmd_if
            while (next_is_else_if(&single_line))
              consume_eols
              local t2 = read
              local inner_if = CmdIf( t2, parse_expression() )
              parse_single_line_statements( inner_if.statements )
              ensure outer_if.else_statements
              outer_if.else_statements.add( inner_if )
              outer_if = inner_if
            endWhile
            if (next_is_else(&single_line))
              consume_eols
              if (next_is(TokenType.KEYWORD_ELSE) and reader.peek(1).type != TokenType.EOL)
                read
                ensure outer_if.else_statements
                parse_single_line_statements( outer_if.else_statements )
              endIf
            endIf
          endIf
          statements.add( cmd_if )
          return true

        elseIf (consume(TokenType.KEYWORD_WHILE))
          local cmd_while = CmdWhile( t, parse_expression() )
          if (parse_statements(cmd_while.statements))
            # Returns true if multi-line statements were parsed
            must_consume( TokenType.KEYWORD_END_WHILE )
          endIf
          statements.add( cmd_while )
          return true

        endIf
      endIf

      if (consume(TokenType.KEYWORD_ACCEPT))
        local name = read_identifier
        statements.add( CmdAcceptInt32(t,Froley.token_def(name).type) )
        return true

      elseIf (consume(TokenType.KEYWORD_CALL))
        local label_name = read_label_name
        statements.add( CmdCall(t,label_name) )
        return true

      elseIf (consume(TokenType.KEYWORD_CLEAR))
        if (consume(TokenType.KEYWORD_BUFFER))
          statements.add( CmdStatement(t,"clear buffer",Opcode.CLEAR_BUFFER) )
          return true
        else
          throw peek.error( "Expected 'buffer'." )
        endIf

      elseIf (consume(TokenType.KEYWORD_COLLECT))
        if (next_is(TokenType.KEYWORD_CH))
          must_consume_register_ch
          statements.add( CmdStatement(t,"collect ch",Opcode.COLLECT_CH) )
          return true
        elseIf (next_is(TokenType.STRING))
          statements.add( CmdCollectString(t,read.text) )
          return true
        elseIf (next_is(TokenType.INTEGER))
          statements.add( CmdCollectCharacter(t,read_integer) )
          return true
        else
          throw t.error( "Syntax error - expected 'ch' or a literal string.")
        endIf
        return true

      elseIf (consume(TokenType.KEYWORD_DISCARD))
        statements.add( CmdStatement(t,"clear buffer",Opcode.CLEAR_BUFFER) )
        statements.add( CmdJump(t,0) )
        return true

      elseIf (consume(TokenType.KEYWORD_ERROR))
        if (consume(TokenType.KEYWORD_BUFFER))
          statements.add( CmdStatement(t,"error buffer",Opcode.ERROR) )
        elseIf (next_is(TokenType.STRING))
          statements.add( CmdStatement(t,"clear buffer",Opcode.CLEAR_BUFFER) )
          statements.add( CmdCollectString(t,read.text) )
          statements.add( CmdStatement(t,"error <message>",Opcode.ERROR) )
        else
          throw peek.error( "Expected 'buffer'." )
        endIf
        return true

      elseIf (consume(TokenType.KEYWORD_GOTO))
        statements.add( CmdGoto(t,read_label_name) )
        return true

      elseIf (consume(TokenType.KEYWORD_HALT))
        statements.add( CmdStatement(t,"halt",Opcode.HALT) )
        return true

      elseIf (consume(TokenType.KEYWORD_PRINT))
        if (consume(TokenType.KEYWORD_BUFFER))
          statements.add( CmdStatement(t,"print buffer",Opcode.PRINT_BUFFER) )
          return true
        elseIf (next_is(TokenType.STRING))
          statements.add( CmdPrintString(t,read.text) )
          if (not consume(TokenType.SYMBOL_SEMICOLON)) must_consume( TokenType.EOL )
          return true
        else
          if (not (next_is(TokenType.EOL) or next_is(TokenType.SYMBOL_SEMICOLON)))
            local expr = parse_expression()
            if (expr.is_ch)
              statements.add( CmdStatement(t,"print ch",Opcode.PRINT_CH) )
              return true
            elseIf (expr.is_count)
              statements.add( CmdStatement(t,"print count",Opcode.PRINT_COUNT) )
              return true
            elseIf (expr.is_integer)
              statements.add( CmdPrintCharacter(t,expr->Int32) )
              return true
            endIf
          endIf
          throw t.error( "Syntax error - valid 'print' arguments are  'ch', 'count', and '<string>'." )
        endIf

      elseIf (consume(TokenType.KEYWORD_RETURN))
        statements.add( CmdStatement(t,"return",Opcode.RETURN) )
        return true

      elseIf (consume(TokenType.KEYWORD_SCAN_DIGITS))
        throw t.error( "Syntax error. Expected 'ch = scanDigits <min-digits>[..<max-digits>] [base <number-base>]'." )

      elseIf (consume(TokenType.KEYWORD_SCAN_TABLE))
        local cmd_scan_table = CmdScanTable( t )
        statements.add( cmd_scan_table )
        parse_scan_table( cmd_scan_table )
        must_consume( TokenType.KEYWORD_END_SCAN_TABLE )
        return true

      elseIf (next_is(TokenType.SYMBOL_LT))
        local name = read_label_name
        must_consume( TokenType.EOL )
        statements.add( CmdLabel(t,name) )
        return true

      elseIf (consume(TokenType.SYMBOL_MINUS_MINUS))
        local target = parse_register
        statements.add( CmdSubtract(t,target,CmdLiteralInt32(t,1)) )
        return true

      elseIf (consume(TokenType.SYMBOL_PLUS_PLUS))
        local target = parse_register
        statements.add( CmdAdd(t,target,CmdLiteralInt32(t,1)) )
        return true

      elseIf (consume(TokenType.KEYWORD_PUSH))
        must_consume( TokenType.KEYWORD_CH )
        statements.add( CmdStatement(t,"push ch",Opcode.PUSH_CH) )
        return true

      else
        local expr = parse_expression()

        local t2 = peek
        if (consume(TokenType.SYMBOL_PLUS_PLUS))
          statements.add( CmdAdd(t,expr,CmdLiteralInt32(t2,1)) )
        elseIf (consume(TokenType.SYMBOL_MINUS_MINUS))
          statements.add( CmdSubtract(t,expr,CmdLiteralInt32(t2,1)) )
        elseIf (consume(TokenType.SYMBOL_PLUS_EQUALS))
          statements.add( CmdAdd(t,expr,parse_expression()) )
        elseIf (consume(TokenType.SYMBOL_MINUS_EQUALS))
          statements.add( CmdSubtract(t,expr,parse_expression()) )
        else
          statements.add( expr )
        endIf
        return true

      endIf

      throw peek.error( "Syntax error - unexpected '$'." (peek->String) )

    method must_consume_register_ch
      local t = peek
      if (consume(TokenType.KEYWORD_CH)) return
      throw t.error( "Register 'ch' expected." )

    method must_consume_register_count
      local t = peek
      if (consume(TokenType.KEYWORD_COUNT)) return
      throw t.error( "Register 'count' expected." )

    method next_is_else_if( &single_line, &multi_line )->Logical
      local original_pos = reader.position
      consume_eols
      if (not next_is(TokenType.KEYWORD_ELSE_IF))
        reader.position = original_pos
        return false
      endIf

      # Scan to just after the elseIf() conditional
      read  # elseIf
      parse_expression()

      if (single_line)
        local result = not next_is( TokenType.EOL )
        reader.position = original_pos
        return result
      else
        local result = next_is( TokenType.EOL )
        reader.position = original_pos
        return result
      endIf

    method next_is_else( &single_line, &multi_line )->Logical
      local original_pos = reader.position
      consume_eols
      if (not next_is(TokenType.KEYWORD_ELSE))
        reader.position = original_pos
        return false
      endIf

      # Scan to just after the else
      read  # else

      if (single_line)
        local result = not next_is( TokenType.EOL )
        reader.position = original_pos
        return result
      else
        local result = next_is( TokenType.EOL )
        reader.position = original_pos
        return result
      endIf

    method parse_access->Cmd
      local t = peek
      local name = read_identifier
      return CmdAccess( t, name )

    method parse_register->Cmd
      local t = peek
      if (consume(TokenType.KEYWORD_CH)) return CmdRegisterCh( t )
      if (consume(TokenType.KEYWORD_COUNT)) return CmdRegisterCount( t )
      throw t.error( "Register 'ch' or 'count' expected." )

    method parse_scan_table( cmd_scan_table:CmdScanTable )
      local patterns = (Pattern,ScanState)[]

      consume_eols
      while (has_another and not next_is(TokenType.KEYWORD_END_SCAN_TABLE))
        if (consume(TokenType.KEYWORD_CASE))
          if (next_is(TokenType.SYMBOL_OPEN_CURLY))
            local pattern = parse_pattern
            local state = ScanState()
            consume( TokenType.SYMBOL_COLON )
            parse_statements( state.statements )
            patterns.add( (pattern,state) )
          else
            local expr = parse_expression()
            local node = cmd_scan_table.start
            if (expr.is_integer)
              node = node.link( expr->Int32->Character )
            elseIf (expr instanceOf CmdLiteralString)
              local st = (expr as CmdLiteralString).value
              node = node.link( forEach in st )
            else
              throw expr.t.error( "Syntax error - expected character, character code, or string." )
            endIf
            consume( TokenType.SYMBOL_COLON )
            parse_statements( node.statements )
          endIf

        elseIf (consume(TokenType.KEYWORD_ACCEPT_ALL))
          local t    = peek
          must_consume( TokenType.SYMBOL_OPEN_BRACKET )
          local name = read_identifier
          must_consume( TokenType.SYMBOL_CLOSE_BRACKET )
          if (Froley.token_defs_by_section.contains(name))
            forEach (def in Froley.section_defs(name))
              if (def.symbol)
                local node = cmd_scan_table.start
                node = node.link( forEach in def.symbol )
                node.statements.add( CmdAcceptInt32(t,def.type) )
              endIf
            endForEach
          else
            throw t.error( "No token definitions for [$] exist." (name) )
          endIf
        elseIf (consume(TokenType.KEYWORD_DISCARD_ALL))
          local t    = peek
          must_consume( TokenType.SYMBOL_OPEN_BRACKET )
          local name = read_identifier
          must_consume( TokenType.SYMBOL_CLOSE_BRACKET )
          if (Froley.token_defs_by_section.contains(name))
            forEach (def in Froley.section_defs(name))
              if (def.symbol)
                local node = cmd_scan_table.start
                node = node.link( forEach in def.symbol )
                node.statements.add( CmdStatement(t,"clear buffer",Opcode.CLEAR_BUFFER) )
                node.statements.add( CmdJump(t,0) )
              endIf
            endForEach
          else
            throw t.error( "No token definitions for [$] exist." (name) )
          endIf
        elseIf (consume(TokenType.KEYWORD_OTHERS))
          consume( TokenType.SYMBOL_COLON )
          parse_statements( cmd_scan_table.start.statements )
        else
          throw peek.error( "Syntax error - expected one of: 'case', 'acceptIdentifier <TOKEN-TYPE>', 'acceptAll [<section-name>]', 'discardAll [<section-name>]', 'others', 'endScanTable'." )
        endIf
        consume_eols
      endWhile

      forEach ((pattern,state) in patterns)
@trace pattern
        PatternGraphBuilder( pattern, state ).apply( cmd_scan_table.start )
        #PatternLoopMaker( pattern ).apply( cmd_scan_table.start )
        #PatternResolver( case_pattern, pattern_match_state ).resolve( cmd_scan_table.start )
      endForEach

    method parse_pattern->Pattern
      local t = peek
      must_consume( TokenType.SYMBOL_OPEN_CURLY )
      return parse_pattern_sequence( t, TokenType.SYMBOL_CLOSE_CURLY )

    method parse_pattern_sequence( t:Token, close_type:TokenType )->Pattern
      local sequence = SequencePattern( t )
      while (reader.has_another and not next_is(close_type))
        sequence.add( parse_pattern_or )
      endWhile
      must_consume( close_type )
      return sequence

    method parse_pattern_or->Pattern
      local pattern = parse_pattern_multiples
      if (not next_is(TokenType.SYMBOL_VERTICAL_BAR)) return pattern

      local result = OrPattern( peek )
      result.add( pattern )
      while (consume(TokenType.SYMBOL_VERTICAL_BAR))
        consume_eols
        result.add( parse_pattern_multiples )
      endWhile
      return result

    method parse_pattern_multiples->Pattern
      local pattern = parse_pattern_term
      if (next_is(TokenType.SYMBOL_ASTERISK))
        return ZeroOrMorePattern( read, pattern )
      else
        return pattern
      endIf

    method parse_pattern_term->Pattern
      local t = peek
      if (consume(TokenType.STRING))
        return StringPattern( t, t.text )
      elseIf (consume(TokenType.KEYWORD_LETTER))
        return LetterPattern( t )
      elseIf (consume(TokenType.KEYWORD_DIGIT))
        return DigitPattern( t )
      elseIf (consume(TokenType.INTEGER))
        return CharacterPattern( t, t->Int32 )
      elseIf (consume(TokenType.SYMBOL_OPEN_PAREN))
        return parse_pattern_sequence( t, TokenType.SYMBOL_CLOSE_PAREN )
      else
        throw t.error( "Syntax error - unexpected '$'." (t->String) )
      endIf

      #{
      if consume( TokenType.SYMBOL_OPEN_PAREN )
      local sequence = SequencePattern()
      while (reader.has_another and not next_is(TokenType.SYMBOL_CLOSE_CURLY))
        sequence.add( parse_pattern_element )
      endWhile
      must_consume( TokenType.SYMBOL_CLOSE_CURLY )
      return sequence
      }#

    method read_identifier->String
      if (next_is(TokenType.IDENTIFIER))
        local name = read->String
        return name
      else
        throw peek.error( "Identifier expected." )
      endIf

    method read_integer->Int32
      if (next_is(TokenType.INTEGER))
        return read->Int32
      else
        throw peek.error( "Integer value expected." )
      endIf

    method read_label_name->String
      must_consume( TokenType.SYMBOL_LT )
      local is_entry_point = consume( TokenType.SYMBOL_LT )
      local name = read->String
      must_consume( TokenType.SYMBOL_GT )
      if (is_entry_point)
        must_consume( TokenType.SYMBOL_GT )
        Froley.entry_points.add( name )
      endIf
      return name

endClass
